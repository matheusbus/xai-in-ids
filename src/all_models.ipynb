{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c50efc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad2ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\n",
    "    \"../../data/raw/NSL-KDD/KDDTrain+.txt\", header=None\n",
    ")\n",
    "test_data = pd.read_csv(\n",
    "    \"../../data/raw/NSL-KDD/KDDTest+.txt\", header=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fbb2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# === 1. Carregar dados ===\n",
    "def load_nslkdd(path, binary_labels=True):\n",
    "    df = pd.read_csv(path, header=None)\n",
    "    df.columns = get_nslkdd_columns(len(df.columns))\n",
    "    \n",
    "    if binary_labels:\n",
    "        df['label'] = df['label'].apply(lambda x: 'normal' if x == 'normal' else 'attack')\n",
    "\n",
    "    X = df.drop(columns=['label'])\n",
    "    y = df['label']\n",
    "    return X, y\n",
    "\n",
    "def get_nslkdd_columns(n):\n",
    "    base = [\n",
    "        \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n",
    "        \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\",\n",
    "        \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n",
    "        \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\",\n",
    "        \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\",\n",
    "        \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\",\n",
    "        \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "        \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\",\n",
    "        \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
    "        \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\",\n",
    "        \"dst_host_srv_rerror_rate\", \"label\"\n",
    "    ]\n",
    "    return base[:n]\n",
    "\n",
    "# === 2. Pré-processamento unificado ===\n",
    "def preprocess(X, y):\n",
    "    # One-hot nos atributos categóricos\n",
    "    cat_cols = ['protocol_type', 'service', 'flag']\n",
    "    X_encoded = pd.get_dummies(X, columns=cat_cols)\n",
    "    feature_names = X_encoded.columns.tolist()\n",
    "\n",
    "    # Escalonar os dados (exceto para RF se quiser pular depois)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_encoded)\n",
    "\n",
    "    # Encode y binário\n",
    "    y_bin = (y != 'normal').astype(int)  # 1=ataque, 0=normal\n",
    "\n",
    "    return X_scaled, y_bin, feature_names, scaler\n",
    "\n",
    "# === 3. Dividir treino/teste ===\n",
    "def split(X, y, test_size=0.3):\n",
    "    return train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "\n",
    "# === 4. Treinar modelos ===\n",
    "def train_models(X_train, X_test, y_train, y_test):\n",
    "    results = {}\n",
    "\n",
    "    # --- Random Forest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    results['RF'] = {\n",
    "        'model': rf,\n",
    "        'accuracy': accuracy_score(y_test, rf.predict(X_test)),\n",
    "        'report': classification_report(y_test, rf.predict(X_test), output_dict=True)\n",
    "    }\n",
    "\n",
    "    # --- MLP\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(50,), max_iter=500, random_state=42)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    results['MLP'] = {\n",
    "        'model': mlp,\n",
    "        'accuracy': accuracy_score(y_test, mlp.predict(X_test)),\n",
    "        'report': classification_report(y_test, mlp.predict(X_test), output_dict=True)\n",
    "    }\n",
    "\n",
    "    # --- LightGBM\n",
    "    lgbm = LGBMClassifier(n_estimators=100, random_state=42)\n",
    "    lgbm.fit(X_train, y_train)\n",
    "    results['LGBM'] = {\n",
    "        'model': lgbm,\n",
    "        'accuracy': accuracy_score(y_test, lgbm.predict(X_test)),\n",
    "        'report': classification_report(y_test, lgbm.predict(X_test), output_dict=True)\n",
    "    }\n",
    "\n",
    "    return results\n",
    "\n",
    "# === 5. Pipeline principal ===\n",
    "def main():\n",
    "    path = \"nsl_kdd.csv\"\n",
    "    X, y = load_nslkdd(path)\n",
    "    X_proc, y_proc, features, scaler = preprocess(X, y)\n",
    "    X_train, X_test, y_train, y_test = split(X_proc, y_proc)\n",
    "\n",
    "    results = train_models(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    for model_name, data in results.items():\n",
    "        print(f\"\\n--- {model_name} ---\")\n",
    "        print(f\"Acurácia: {data['accuracy']:.4f}\")\n",
    "        print(pd.DataFrame(data['report']).transpose())\n",
    "\n",
    "        # Salvar modelo\n",
    "        joblib.dump(data['model'], f\"models/{model_name.lower()}.pkl\")\n",
    "\n",
    "    # Salvar dados e scaler para XAI\n",
    "    joblib.dump((X_test, y_test, features, scaler), \"models/test_data.pkl\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
